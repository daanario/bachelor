{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d6df25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f7c359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba-based indexing function from StackOverflow\n",
    "# https://stackoverflow.com/a/41578614\n",
    "\n",
    "@njit\n",
    "def index(array, item):\n",
    "    \"\"\"\n",
    "    Find the index of the first occurrence of a given item in a numpy array.\n",
    "\n",
    "        Parameters:\n",
    "                array (Array): The array to search in.\n",
    "                item (float): The item to search for.\n",
    "\n",
    "        Returns:\n",
    "                Tuple[int, ...]: The index of the first occurrence of `item` in `array`.\n",
    "                The returned index is a tuple of integers representing the position\n",
    "                of the item along each dimension of the array\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the item is not found in the array.\n",
    "    \"\"\"\n",
    "    for idx, val in np.ndenumerate(array):\n",
    "        if val == item:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b5fec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player2D:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the player for 2 dimensional game. \n",
    "\n",
    "            Parameters:\n",
    "                    None\n",
    "            Returns:\n",
    "                    Nothing, but contains the list for profits.       \n",
    "        \"\"\"\n",
    "        self.profits = list()\n",
    "\n",
    "    def BR(self):\n",
    "        \"\"\"\n",
    "        Best response function for the Player.  \n",
    "\n",
    "            Parameters:\n",
    "                    None\n",
    "            Returns:\n",
    "                    Nothing at the moment.       \n",
    "        \"\"\"\n",
    "        return\n",
    "    def demand(self, p1:float, p2:float) -> float:\n",
    "        \"\"\"\n",
    "        Demand function for the player. \n",
    "\n",
    "            Parameters:\n",
    "                    p1 (float): the price for player 0\n",
    "                    p2 (float): the price for player 1 \n",
    "            Returns:\n",
    "                    Returns the share of the market that the player gets.        \n",
    "        \"\"\"\n",
    "        if (p1 < p2):\n",
    "            return 1 - p1\n",
    "        elif (p1 == p2):\n",
    "            return 0.5 * (1 - p1)\n",
    "        elif (p1 > p2):\n",
    "            return 0\n",
    "    def profit(self, p1:float, p2:float):\n",
    "        \"\"\"\n",
    "        Profit function for the player. \n",
    "\n",
    "            Parameters:\n",
    "                    p1 (float): the price for player 0\n",
    "                    p2 (float): the price for player 1 \n",
    "            Returns:\n",
    "                    The profit of player 0.        \n",
    "        \"\"\"\n",
    "        return p1 * self.demand(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "621815ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearner2D(Player2D):\n",
    "    # ONLY WORKS IN 2 DIMENSIONS FOR NOW\n",
    "    def __init__(self, k, T):\n",
    "        \"\"\"\n",
    "        Initializes the Q-learner. \n",
    "\n",
    "            Parameters:\n",
    "                    k (integer): Number of prices. \n",
    "                    T (interger): Number of runs\n",
    "            Returns:\n",
    "                    Nothing, but initilalizes all variables for the Q-learner.        \n",
    "        \"\"\"\n",
    "        Player2D.__init__(self)\n",
    "        \n",
    "        self.Q_table = np.zeros([k] * 2)\n",
    "        \n",
    "        self.prices = np.linspace(0, 1, k, endpoint=True)\n",
    "        \n",
    "        self.ps = np.empty(T)\n",
    "        self.ps.fill(np.nan)\n",
    "        \n",
    "        self.alpha = 0.3\n",
    "        self.delta = 0.95\n",
    "        self.t = 0\n",
    "        self.theta = -(1/1000000)**(1/T) + 1\n",
    "        self.epsilon = (1 - self.theta)**self.t\n",
    "    def initialize_start(self):\n",
    "        \"\"\"\n",
    "        Initializes the starting prices for the Q-learner. This uses 2 time periods, resulting in t = 2.\n",
    "\n",
    "            Parameters:\n",
    "                    None\n",
    "            Returns:\n",
    "                    Nothing, but updates starting prices for the two first periods.\n",
    "        \"\"\"\n",
    "        self.ps[0:2] = np.random.choice(self.prices)\n",
    "        self.t = 2\n",
    "    def update(self, t, s, s_next):\n",
    "        \"\"\"\n",
    "        Part of the exploration module.\n",
    "        Updates the Q-table for this Q-learner (1 time period)\n",
    "\n",
    "            Parameters:\n",
    "                    s (float): Our state (opponent price) for t\n",
    "                    s_next (float): Our state (opponent price) for t+1\n",
    "\n",
    "            Returns:\n",
    "                    Nothing, but updates Q-table with a new Q-value.\n",
    "        \"\"\"\n",
    "        delta = self.delta\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        p = self.ps[t]\n",
    "        #print(p)\n",
    "        prev_est = self.Q_table[index(self.prices, p), index(self.prices, s)]\n",
    "        maxed_Q = max(self.Q_table[:, index(self.prices, s_next)])\n",
    "        new_est = self.profit(p, s) + delta * self.profit(p, s_next) + delta**2 * maxed_Q\n",
    "        self.Q_table[index(self.prices, p), index(self.prices, s)] = (1 - self.alpha) * prev_est + alpha * new_est\n",
    "        return\n",
    "        \n",
    "    def set_price(self, s):\n",
    "        \"\"\"\n",
    "        Part of the action module.\n",
    "        Sets the price randomly with probability epsilon or sets the price that maximizes the Q-value\n",
    "        given the state (opponent price) with probability (1 - epsilon).\n",
    "        \n",
    "            Parameters: \n",
    "                s (float): Our state (opponent price) for t\n",
    "            Returns:\n",
    "                Nothing, but puts best response price from array of possible prices in price array\n",
    "        \"\"\"\n",
    "        if self.epsilon >= np.random.uniform(0,1):\n",
    "            self.ps[self.t] = np.random.choice(self.prices)\n",
    "            return \n",
    "        else: \n",
    "            maxedQ_idx = np.argmax(self.Q_table[:, index(self.prices, s)])\n",
    "            self.ps[self.t] = self.prices[maxedQ_idx]\n",
    "            return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1e43bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, k, T, N):\n",
    "        \"\"\"\n",
    "        Initialize a new instance of the Game class.\n",
    "\n",
    "        Parameters:\n",
    "                k (float): The number of prices. \n",
    "                T (float): The total time to simulate.\n",
    "                N (int): The number of time steps to use in the simulation.\n",
    "        Returns: \n",
    "                Nothing \n",
    "        \"\"\"\n",
    "\n",
    "        self.k = k\n",
    "        self.t = 0\n",
    "        self.T = T\n",
    "        self.N = N\n",
    "    def update_profit(self, player : Player2D, s):\n",
    "        \"\"\"\n",
    "        Update the profit of a player based on the current price and state.\n",
    "\n",
    "        This method calculates the profit of the player using the current price\n",
    "        and state, and appends it to the player's list of profits.\n",
    "\n",
    "        Parameters:\n",
    "            player (Player2D): The player whose profit should be updated.\n",
    "            s (float): The current state.\n",
    "\n",
    "        Returns:\n",
    "            Nothing but updates the profit array.\n",
    "        \"\"\"\n",
    "        price = player.ps[player.t]\n",
    "        player.profits.append(player.profit(price, s))\n",
    "    \n",
    "    def simulate(self):\n",
    "        # TODO: figure out difference in t between Q-learner and Game classes\n",
    "        \n",
    "        qlearner0 = Qlearner2D(self.k,self.T) #initialize players\n",
    "        qlearner1 = Qlearner2D(self.k, self.T)\n",
    "        \n",
    "        players = [qlearner0, qlearner1]\n",
    "        \n",
    "        i = 0\n",
    "        j = 1\n",
    "\n",
    "        profitabilities0 = []\n",
    "        profitabilities1 = []\n",
    "        \n",
    "        qlearner0.initialize_start()\n",
    "        qlearner1.initialize_start()\n",
    "        self.t = 2 # after inititialization, t = 2\n",
    "        while self.t < self.T:\n",
    "            t = self.t\n",
    "            players[i].t = self.t\n",
    "            players[j].t = self.t\n",
    "            \n",
    "            # exploration module\n",
    "            players[i].update(t-2, players[j].ps[t-2], players[j].ps[t-1])\n",
    "\n",
    "            # action module\n",
    "            players[i].set_price(players[j].ps[t-1]) # set price according to state (player j's current price)\n",
    "            players[j].ps[t] = players[j].ps[t-1]\n",
    "            \n",
    "            # write profits for firm i and j\n",
    "            self.update_profit(players[i], players[j].ps[t])\n",
    "            \n",
    "            \n",
    "            self.update_profit(players[j], players[i].ps[t])\n",
    "                \n",
    "            #compute avg profitability of last 1000 runs\n",
    "            if t % 50000 == 0:\n",
    "                profitability0 = np.sum(players[0].profits[(t-1000):t])/1000\n",
    "                profitability1 = np.sum(players[1].profits[(t-1000):t])/1000\n",
    "                profitabilities0.append(profitability0)\n",
    "                profitabilities1.append(profitability1)\n",
    "\n",
    "            # calculate new epsilon using decay parameter\n",
    "            players[i].epsilon = (1 - players[i].theta)**t\n",
    "            players[j].epsilon = (1 - players[j].theta)**t\n",
    "            \n",
    "            tmp = i\n",
    "            i = j\n",
    "            j = tmp\n",
    "            self.t += 1\n",
    "        return profitabilities0, profitabilities1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c1894d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create game and simulate\n",
    "\n",
    "game = Game(6, 250000, 1)\n",
    "prof0, prof1 = game.simulate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
